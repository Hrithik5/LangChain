{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65f56ee4",
   "metadata": {},
   "source": [
    "## Simple MultiAI Agent Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec664ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, Annotated, List, Literal\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9096b1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "from langgraph.graph import StateGraph, END, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "## Define the state\n",
    "class AgentState(MessagesState):\n",
    "    next_agent:str #which agent should go next \n",
    "\n",
    "# Create simple tools\n",
    "@tool\n",
    "def search_web(query: str) -> str:\n",
    "    \"\"\"Search the web for information.\"\"\"\n",
    "    # Using Tavily for web search\n",
    "    search = TavilySearchResults(max_results=3)\n",
    "    results = search.invoke(query)\n",
    "    return str(results)\n",
    "\n",
    "@tool\n",
    "def write_summary(content: str) -> str:\n",
    "    \"\"\"Write a summary of the provided content.\"\"\"\n",
    "    # Simple summary generation\n",
    "    summary = f\"Summary of findings:\\n\\n{content[:500]}...\"\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add441e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm=init_chat_model(\"groq:llama-3.1-8b-instant\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a88ae9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define agent functions (simpler approach)\n",
    "def researcher_agent(state: AgentState):\n",
    "    \"\"\"Researcher agent that searches for information\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # Add system message for context\n",
    "    system_msg = SystemMessage(content=\"You are a research assistant. Use the search_web tool to find information about the user's request.\")\n",
    "    \n",
    "    # Call LLM with tools\n",
    "    researcher_llm = llm.bind_tools([search_web])\n",
    "    response = researcher_llm.invoke([system_msg] + messages)\n",
    "    \n",
    "    # Return the response and route to writer\n",
    "    return {\n",
    "        \"messages\": [response],\n",
    "        \"next_agent\": \"writer\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60b80007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writer_agent(state: AgentState):\n",
    "    \"\"\"Writer agent that creates summaries\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # Add system message\n",
    "    system_msg = SystemMessage(content=\"You are a technical writer. Review the conversation and create a clear, concise summary of the findings.\")\n",
    "    \n",
    "    # Simple completion without tools\n",
    "    response = llm.invoke([system_msg] + messages)\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [response],\n",
    "        \"next_agent\": \"end\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96ed2690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool executor node\n",
    "def execute_tools(state: AgentState):\n",
    "    \"\"\"Execute any pending tool calls\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # Check if there are tool calls to execute\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        # Create tool node and execute\n",
    "        tool_node = ToolNode([search_web, write_summary])\n",
    "        response = tool_node.invoke(state)\n",
    "        return response\n",
    "    \n",
    "    # No tools to execute\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eab7c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build graph\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"researcher\", researcher_agent)\n",
    "workflow.add_node(\"writer\", writer_agent)\n",
    "\n",
    "# Define flow\n",
    "workflow.set_entry_point(\"researcher\")\n",
    "workflow.add_edge(\"researcher\", \"writer\")\n",
    "workflow.add_edge(\"writer\", END)\n",
    "final_workflow=workflow.compile()\n",
    "\n",
    "final_workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aec0c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=final_workflow.invoke({\"messages\":\"Reasearch about the usecase of agentic ai in business\"})\n",
    "response[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb244ea6",
   "metadata": {},
   "source": [
    "## Simple Hierarchical Multi-Agent System with Groq\n",
    "\n",
    "Shows how to organize agents in teams with team leaders.\n",
    "\n",
    "Structure:\n",
    "\n",
    "CEO (top level)\n",
    "- Research Team Leader ->\n",
    "Data Researcher,\n",
    "Market Researcher\n",
    "- Writing Team Leader -> \n",
    "Technical Writer,\n",
    "Summary Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d1702e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List, Literal, Dict, Any\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, END, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0aa07bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# State Definition\n",
    "# ===================================\n",
    "\n",
    "class SupervisorState(MessagesState):\n",
    "    \"\"\"State for the multi-agent system\"\"\"\n",
    "    next_agent: str = \"\"\n",
    "    research_data: str = \"\"\n",
    "    analysis: str = \"\"\n",
    "    final_report: str = \"\"\n",
    "    task_complete: bool = False\n",
    "    current_task: str = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc473e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# Supervisor with Groq LLM\n",
    "# ===================================\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "def create_supervisor_chain():\n",
    "    \"\"\"Creates the supervisor decision chain\"\"\"\n",
    "    \n",
    "    supervisor_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are a supervisor managing a team of agents:\n",
    "        \n",
    "1. Researcher - Gathers information and data\n",
    "2. Analyst - Analyzes data and provides insights  \n",
    "3. Writer - Creates reports and summaries\n",
    "\n",
    "Based on the current state and conversation, decide which agent should work next.\n",
    "If the task is complete, respond with 'DONE'.\n",
    "\n",
    "Current state:\n",
    "- Has research data: {has_research}\n",
    "- Has analysis: {has_analysis}\n",
    "- Has report: {has_report}\n",
    "\n",
    "Respond with ONLY the agent name (researcher/analyst/writer) or 'DONE'.\n",
    "\"\"\"),\n",
    "        (\"human\", \"{task}\")\n",
    "    ])\n",
    "    \n",
    "    return supervisor_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ce04f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervisor_agent(state: SupervisorState) -> Dict:\n",
    "    \"\"\"Supervisor decides next agent using Groq LLM\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    task = messages[-1].content if messages else \"No task\"\n",
    "    \n",
    "    # Check what's been completed\n",
    "    has_research = bool(state.get(\"research_data\", \"\"))\n",
    "    has_analysis = bool(state.get(\"analysis\", \"\"))\n",
    "    has_report = bool(state.get(\"final_report\", \"\"))\n",
    "    \n",
    "    # Get LLM decision\n",
    "    chain = create_supervisor_chain()\n",
    "    decision = chain.invoke({\n",
    "        \"task\": task,\n",
    "        \"has_research\": has_research,\n",
    "        \"has_analysis\": has_analysis,\n",
    "        \"has_report\": has_report\n",
    "    })\n",
    "    \n",
    "    # Parse decision\n",
    "    decision_text = decision.content.strip().lower()\n",
    "    print(decision_text)\n",
    "    \n",
    "    # Determine next agent\n",
    "    if \"done\" in decision_text or has_report:\n",
    "        next_agent = \"end\"\n",
    "        supervisor_msg = \"âœ… Supervisor: All tasks complete! Great work team.\"\n",
    "    elif \"researcher\" in decision_text or not has_research:\n",
    "        next_agent = \"researcher\"\n",
    "        supervisor_msg = \"ðŸ“‹ Supervisor: Let's start with research. Assigning to Researcher...\"\n",
    "    elif \"analyst\" in decision_text or (has_research and not has_analysis):\n",
    "        next_agent = \"analyst\"\n",
    "        supervisor_msg = \"ðŸ“‹ Supervisor: Research done. Time for analysis. Assigning to Analyst...\"\n",
    "    elif \"writer\" in decision_text or (has_analysis and not has_report):\n",
    "        next_agent = \"writer\"\n",
    "        supervisor_msg = \"ðŸ“‹ Supervisor: Analysis complete. Let's create the report. Assigning to Writer...\"\n",
    "    else:\n",
    "        next_agent = \"end\"\n",
    "        supervisor_msg = \"âœ… Supervisor: Task seems complete.\"\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=supervisor_msg)],\n",
    "        \"next_agent\": next_agent,\n",
    "        \"current_task\": task\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d391f613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# Agent 1: Researcher (using Groq)\n",
    "# ===================================\n",
    "\n",
    "def researcher_agent(state: SupervisorState) -> Dict:\n",
    "    \"\"\"Researcher uses Groq to gather information\"\"\"\n",
    "    \n",
    "    task = state.get(\"current_task\", \"research topic\")\n",
    "    \n",
    "    # Create research prompt\n",
    "    research_prompt = f\"\"\"As a research specialist, provide comprehensive information about: {task}\n",
    "\n",
    "    Include:\n",
    "    1. Key facts and background\n",
    "    2. Current trends or developments\n",
    "    3. Important statistics or data points\n",
    "    4. Notable examples or case studies\n",
    "    \n",
    "    Be concise but thorough.\"\"\"\n",
    "    \n",
    "    # Get research from LLM\n",
    "    research_response = llm.invoke([HumanMessage(content=research_prompt)])\n",
    "    research_data = research_response.content\n",
    "    \n",
    "    # Create agent message\n",
    "    agent_message = f\"ðŸ” Researcher: I've completed the research on '{task}'.\\n\\nKey findings:\\n{research_data[:500]}...\"\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=agent_message)],\n",
    "        \"research_data\": research_data,\n",
    "        \"next_agent\": \"supervisor\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "525ce82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# Agent 2: Analyst (using Groq)\n",
    "# ===================================\n",
    "\n",
    "def analyst_agent(state: SupervisorState) -> Dict:\n",
    "    \"\"\"Analyst uses Groq to analyze the research\"\"\"\n",
    "    \n",
    "    research_data = state.get(\"research_data\", \"\")\n",
    "    task = state.get(\"current_task\", \"\")\n",
    "    \n",
    "    # Create analysis prompt\n",
    "    analysis_prompt = f\"\"\"As a data analyst, analyze this research data and provide insights:\n",
    "\n",
    "Research Data:\n",
    "{research_data}\n",
    "\n",
    "Provide:\n",
    "1. Key insights and patterns\n",
    "2. Strategic implications\n",
    "3. Risks and opportunities\n",
    "4. Recommendations\n",
    "\n",
    "Focus on actionable insights related to: {task}\"\"\"\n",
    "    \n",
    "    # Get analysis from LLM\n",
    "    analysis_response = llm.invoke([HumanMessage(content=analysis_prompt)])\n",
    "    analysis = analysis_response.content\n",
    "    \n",
    "    # Create agent message\n",
    "    agent_message = f\"ðŸ“Š Analyst: I've completed the analysis.\\n\\nTop insights:\\n{analysis[:400]}...\"\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=agent_message)],\n",
    "        \"analysis\": analysis,\n",
    "        \"next_agent\": \"supervisor\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30b70998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# Agent 3: Writer (using Groq)\n",
    "# ===================================\n",
    "\n",
    "def writer_agent(state: SupervisorState) -> Dict:\n",
    "    \"\"\"Writer uses Groq to create final report\"\"\"\n",
    "    \n",
    "    research_data = state.get(\"research_data\", \"\")\n",
    "    analysis = state.get(\"analysis\", \"\")\n",
    "    task = state.get(\"current_task\", \"\")\n",
    "    \n",
    "    # Create writing prompt\n",
    "    writing_prompt = f\"\"\"As a professional writer, create an executive report based on:\n",
    "\n",
    "Task: {task}\n",
    "\n",
    "Research Findings:\n",
    "{research_data[:1000]}\n",
    "\n",
    "Analysis:\n",
    "{analysis[:1000]}\n",
    "\n",
    "Create a well-structured report with:\n",
    "1. Executive Summary\n",
    "2. Key Findings  \n",
    "3. Analysis & Insights\n",
    "4. Recommendations\n",
    "5. Conclusion\n",
    "\n",
    "Keep it professional and concise.\"\"\"\n",
    "    \n",
    "    # Get report from LLM\n",
    "    report_response = llm.invoke([HumanMessage(content=writing_prompt)])\n",
    "    report = report_response.content\n",
    "    \n",
    "    # Create final formatted report\n",
    "    final_report = f\"\"\"\n",
    "ðŸ“„ FINAL REPORT\n",
    "{'='*50}\n",
    "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n",
    "Topic: {task}\n",
    "{'='*50}\n",
    "\n",
    "{report}\n",
    "\n",
    "{'='*50}\n",
    "Report compiled by Multi-Agent AI System powered by Groq\n",
    "\"\"\"\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=f\"âœï¸ Writer: Report complete! See below for the full document.\")],\n",
    "        \"final_report\": final_report,\n",
    "        \"next_agent\": \"supervisor\",\n",
    "        \"task_complete\": True\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eadb5705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# Router Function\n",
    "# ===================================\n",
    "\n",
    "def router(state: SupervisorState) -> Literal[\"supervisor\", \"researcher\", \"analyst\", \"writer\", \"__end__\"]:\n",
    "    \"\"\"Routes to next agent based on state\"\"\"\n",
    "    \n",
    "    next_agent = state.get(\"next_agent\", \"supervisor\")\n",
    "    \n",
    "    if next_agent == \"end\" or state.get(\"task_complete\", False):\n",
    "        return END\n",
    "        \n",
    "    if next_agent in [\"supervisor\", \"researcher\", \"analyst\", \"writer\"]:\n",
    "        return next_agent\n",
    "        \n",
    "    return \"supervisor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ededd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create workflow\n",
    "workflow = StateGraph(SupervisorState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"supervisor\", supervisor_agent)\n",
    "workflow.add_node(\"researcher\", researcher_agent)\n",
    "workflow.add_node(\"analyst\", analyst_agent)\n",
    "workflow.add_node(\"writer\", writer_agent)\n",
    "\n",
    "# Set entry point\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "# Add routing\n",
    "for node in [\"supervisor\", \"researcher\", \"analyst\", \"writer\"]:\n",
    "    workflow.add_conditional_edges(\n",
    "        node,\n",
    "        router,\n",
    "        {\n",
    "            \"supervisor\": \"supervisor\",\n",
    "            \"researcher\": \"researcher\",\n",
    "            \"analyst\": \"analyst\",\n",
    "            \"writer\": \"writer\",\n",
    "            END: END\n",
    "        }\n",
    "    )\n",
    "\n",
    "graph=workflow.compile()\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a94ce06",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=graph.invoke(HumanMessage(content=\"What are the benefits and risks of AI in healthcare?\"))\n",
    "response['final_report']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
